# Notes: Реализация Issue #83 и #84 в коде

Этот файл — короткая техническая памятка по тому, **как именно** реализованы задачи:

- **Issue #83 — Data Quality Gates: валидация данных перед импортом**
- **Issue #84 — Карантинная таблица для некорректных данных**

Документ полезен, если нужно быстро сориентироваться в коде, готовить обзор для ревью/диплома
или дорабатывать ETL.

---

## Issue #83 — Data Quality Gates (валидация данных перед импортом)

### Где живёт логика

Основные места:

- `scripts/load_csv.py`
  - точка входа `main()`, читает Excel/CSV в `pandas.DataFrame`;
  - управляет потоком: парсинг → валидация → разбор на «хорошие» и «плохие» строки → запись в БД.
- `scripts/load_utils.py`
  - функции работы с БД: подключение, upsert цен, создание `envelope` и т.п.;
  - функция `upsert_records(df, asof_dt, ...)` получает **уже отфильтрованные, валидные** строки;
  - отдельные вспомогательные функции для сохранения строк, не прошедших DQ, в карантин (см. Issue #84).
- Модуль валидации (см. `tests/unit/test_data_quality.py`, `tests/unit/test_validation.py`)
  - валидация обязательных полей (`code`, цена и т.д.);
  - проверки типов и диапазонов (цена, скидка, дата действия и пр.);
  - формирование списка ошибок по каждой строке.

### Как устроен Data Quality pipeline

Упрощённо поток в `load_csv` выглядит так:

1. Прочитать файл (Excel/CSV) в DataFrame.
2. Для каждой строки вызвать набор DQ-правил (см. тесты в `tests/unit/test_data_quality.py`).
3. Разделить строки на две группы:
   - **валидные** — проходят все проверки;
   - **невалидные** — имеют хотя бы одну ошибку (список описаний хранится в `dq_errors`).
4. Валидные строки передаются в `upsert_records(...)`, которая:
   - вызывает хранимые процедуры/SQL (`upsert_price` и т.п.);
   - обновляет таблицы с ценами и историей.
5. Невалидные строки **не попадают** в боевые таблицы, а сохраняются в `price_list_quarantine`
   (см. Issue #84).

Это обеспечивает «data quality gate» перед БД: всё, что не прошло валидацию, остаётся в карантине
и не ломает основную схему.

### Как это тестируется

Unit-тесты:

- `tests/unit/test_data_quality.py`
  - проверяет точечные DQ-правила (какие строки считаются валидными/невалидными);
- `tests/unit/test_load_csv.py`
  - проверяет, что `load_csv` корректно реагирует на разные входные файлы,
    в том числе с ошибками;
- `tests/unit/test_load_utils.py`
  - тестирует работу `upsert_records`, подключение к БД и вспомогательные функции.

Интеграционные тесты (см. также Issue #84):

- `tests/integration/test_price_import_etl.py`
  - прогоняет полный цикл импорта прайсов в реальную Postgres (через Docker);
  - проверяет, что данные в БД и в API согласованы, история цен строится корректно.

---

## Issue #84 — Карантинная таблица для некорректных данных

### Схема таблицы

Таблица создаётся миграцией:

- `db/migrations/0010_price-list-quarantine.sql`

Столбцы (по `\d price_list_quarantine`):

- `id` — surrogate primary key;
- `envelope_id` — внешний ключ на сущность загрузки (конкретный импорт / файл прайса);
- `code` — код товара из прайса (может быть `NULL`, если строка вообще «сломана»);
- `raw_row` — сырые данные строки (обычно текст/JSON-представление исходной строки файла);
- `dq_errors` — текст/JSON с описанием ошибок валидации;
- `created_at` — время помещения строки в карантин.

### Как строки попадают в карантин

В ETL-пайплайне `load_csv` после применения DQ-правил:

1. Для каждой строки формируется список ошибок (может быть пустым).
2. Если список пуст — строка идёт в `upsert_records(...)` и попадает в боевые таблицы.
3. Если список **не пуст** — строка не импортируется в боевые таблицы и вместо этого:
   - сериализуется в `raw_row`;
   - список ошибок преобразуется в `dq_errors` (человеко-читаемый текст/JSON);
   - вместе с `envelope_id` и `code` сохраняется в `price_list_quarantine`.

Таким образом, таблица карантина выполняет две функции:

- защищает основную БД от «кривых» строк;
- даёт прозрачную картину того, **что именно** не загрузилось и почему.

### Где в коде искать вставку в карантин

Высокоуровнево:

- `scripts/load_csv.py`
  - после DQ-валидации формирует две выборки: «good» и «bad» строки;
  - вызывает функции из `load_utils` для записи в карантин.
- `scripts/load_utils.py`
  - функции уровня «работа с БД» для карантина (insert в `price_list_quarantine`);
  - опирается на активный `envelope_id`, который создаётся на каждую загрузку файла.

Логика спроектирована так, чтобы при необходимости можно было:

- добавлять новые поля в `price_list_quarantine` (например, отдельные флаги);
- расширять набор DQ-правил, не трогая SQL-миграцию.

### Как смотреть карантин в рантайме

С помощью цели `show-quarantine` в `Makefile`:

```bash
make show-quarantine
```

Она выполняет запрос вида:

```sql
SELECT id, envelope_id, code, dq_errors, created_at
FROM price_list_quarantine
ORDER BY created_at DESC
LIMIT 50;
```

Если импорты проходят чисто, результат будет `(0 rows)`.
Если есть ошибки, здесь видны последние проблемные строки и причина их попадания в карантин.

---

## Быстрая проверка, что всё работает вместе (E2E)

Ниже — краткий сценарий проверки связки Issue #83 + #84 на Windows
(подробности см. `docs/dev/dev-setup-windows.md`).

```powershell
cd D:\Documents\JetBrainsIDEProjects\PyCharmProjects\wine-assistant
.\.venv\Scriptsctivate

# 1. Полностью пересоздать окружение Docker
make db-reset

# 2. Загрузить набор прайсов (валидные файлы из data\inbox)
make load-price EXCEL_PATH=".\data\inbox5_06_03 Прайс_Легенда_Виноделия.xlsx"
...
make load-price EXCEL_PATH=".\data\inbox5_10_27 Прайс_Легенда_Виноделия.xlsx"

# 3. Проверить карантин
make show-quarantine   # в базовом happy-path сценарии (0 rows)

# 4. Прогнать тесты и линтер
make test-unit         # unit-тесты (включая data quality)
make check             # ruff + полный pytest
```

Если все шаги проходят, можно считать, что реализация Issue #83 и #84
корректно работает на актуальной версии БД, ETL и API.
